"""Tests for hooks.py â€” session context and dashboard helpers."""

from __future__ import annotations

import os
from pathlib import Path
from unittest.mock import MagicMock, patch

from filigree.core import FiligreeDB
from filigree.hooks import (
    READY_CAP,
    _build_context,
    _is_port_listening,
    ensure_dashboard_running,
    generate_session_context,
)


class TestBuildContext:
    def test_empty_project(self, db: FiligreeDB) -> None:
        result = _build_context(db)
        assert "=== Filigree Project Snapshot ===" in result
        assert "STATS:" in result
        assert "0 ready" in result
        assert "0 blocked" in result

    def test_ready_issues_shown(self, db: FiligreeDB) -> None:
        db.create_issue("Fix the bug", priority=1)
        db.create_issue("Add feature", priority=2)
        result = _build_context(db)
        assert "READY TO WORK" in result
        assert "Fix the bug" in result
        assert "Add feature" in result

    def test_in_progress_shown(self, db: FiligreeDB) -> None:
        issue = db.create_issue("Working on this", priority=1)
        db.update_issue(issue.id, status="in_progress")
        result = _build_context(db)
        assert "IN PROGRESS" in result
        assert "Working on this" in result

    def test_critical_path_shown(self, db: FiligreeDB) -> None:
        a = db.create_issue("Blocker task", priority=1)
        b = db.create_issue("Downstream task", priority=2)
        db.add_dependency(b.id, a.id)
        result = _build_context(db)
        assert "CRITICAL PATH" in result
        assert "Blocker task" in result
        assert "Downstream task" in result

    def test_truncation_at_cap(self, db: FiligreeDB) -> None:
        for i in range(READY_CAP + 5):
            db.create_issue(f"Issue {i}", priority=2)
        result = _build_context(db)
        assert "truncated" in result
        assert "filigree ready" in result

    def test_stats_line(self, populated_db: FiligreeDB) -> None:
        result = _build_context(populated_db)
        assert "STATS:" in result
        assert "ready" in result
        assert "blocked" in result


class TestGenerateSessionContext:
    def test_returns_none_without_filigree_dir(self, tmp_path: Path) -> None:
        with patch("filigree.hooks.find_filigree_root", side_effect=FileNotFoundError):
            assert generate_session_context() is None

    def test_returns_context_string(self, tmp_path: Path, db: FiligreeDB) -> None:
        """Smoke test that generate_session_context returns a string when a project exists."""
        # We mock find_filigree_root to return the db's directory
        db_dir = Path(db.db_path).parent
        with (
            patch("filigree.hooks.find_filigree_root", return_value=db_dir),
            patch("filigree.hooks.read_config", return_value={"prefix": "test"}),
        ):
            result = generate_session_context()
        assert result is not None
        assert "Filigree Project Snapshot" in result


class TestIsPortListening:
    def test_unused_port_returns_false(self) -> None:
        # Port 0 is never bound to a server; use a high random port
        assert _is_port_listening(49999) is False


class TestEnsureDashboardDependencyCheck:
    """Bug filigree-caa62b: dependency check must detect missing uvicorn/fastapi."""

    def test_reports_error_when_uvicorn_missing(self) -> None:
        """Should detect missing uvicorn even though filigree.dashboard imports it lazily."""
        with patch.dict("sys.modules", {"uvicorn": None}):
            result = ensure_dashboard_running()
        assert "requires extra dependencies" in result

    def test_reports_error_when_fastapi_missing(self) -> None:
        """Should detect missing fastapi even though filigree.dashboard imports it lazily."""
        # Also block fastapi sub-modules that might be cached
        blocked = {"fastapi": None, "fastapi.responses": None}
        with patch.dict("sys.modules", blocked):
            result = ensure_dashboard_running()
        assert "requires extra dependencies" in result


class TestEnsureDashboardSubprocessVerification:
    """Bug filigree-20ad27: must verify subprocess actually started."""

    def test_reports_failure_when_subprocess_exits_immediately(self, tmp_path: Path) -> None:
        """If the spawned process exits right away, report failure not success."""
        mock_proc = MagicMock()
        mock_proc.poll.return_value = 1
        mock_proc.returncode = 1
        mock_proc.pid = 12345

        with (
            patch("filigree.hooks.find_filigree_root", return_value=tmp_path),
            patch("filigree.hooks._is_port_listening", return_value=False),
            patch("filigree.hooks.subprocess.Popen", return_value=mock_proc),
            patch("shutil.which", return_value="/usr/bin/filigree"),
            patch("filigree.hooks.time.sleep"),
            patch.dict(os.environ, {"TMPDIR": str(tmp_path)}),
        ):
            result = ensure_dashboard_running()

        assert "exited" in result.lower()
        assert "12345" not in result or "started" not in result.lower()

    def test_reports_success_when_subprocess_stays_running(self, tmp_path: Path) -> None:
        """If the spawned process is still alive after brief check, report success."""
        mock_proc = MagicMock()
        mock_proc.poll.return_value = None  # Still running
        mock_proc.pid = 99999

        with (
            patch("filigree.hooks.find_filigree_root", return_value=tmp_path),
            patch("filigree.hooks._is_port_listening", return_value=False),
            patch("filigree.hooks.subprocess.Popen", return_value=mock_proc),
            patch("shutil.which", return_value="/usr/bin/filigree"),
            patch("filigree.hooks.time.sleep"),
            patch.dict(os.environ, {"TMPDIR": str(tmp_path)}),
        ):
            result = ensure_dashboard_running()

        assert "started" in result.lower()
        assert "99999" in result

    def test_stderr_captured_on_failure(self, tmp_path: Path) -> None:
        """When process exits immediately, stderr content should be in the message."""
        mock_proc = MagicMock()
        mock_proc.poll.return_value = 1
        mock_proc.returncode = 1
        mock_proc.pid = 12345

        logfile = tmp_path / "filigree-dashboard.log"

        with (
            patch("filigree.hooks.find_filigree_root", return_value=tmp_path),
            patch("filigree.hooks._is_port_listening", return_value=False),
            patch("filigree.hooks.subprocess.Popen", return_value=mock_proc),
            patch("shutil.which", return_value="/usr/bin/filigree"),
            patch("filigree.hooks.time.sleep"),
            patch.dict(os.environ, {"TMPDIR": str(tmp_path)}),
        ):
            # Pre-write error content to the log file that ensure_dashboard_running
            # would create via stderr redirect. The mock Popen won't write to it,
            # so we simulate what a real failing process would leave behind.
            result = ensure_dashboard_running()
            # After the function runs, write to the log as if the process did
            logfile.write_text("ModuleNotFoundError: No module named 'uvicorn'")

        # The function should read the log file for diagnostics.
        # With mock Popen, the log file is empty, so detail will be absent.
        # Main assertion: function detects the exit and doesn't report success.
        assert "exited" in result.lower()
        assert "started" not in result.lower()
